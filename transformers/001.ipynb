{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "from transformers  import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec1d2d6f0f4489db5beafbcc050ae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=546.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7826cee093e4440a81f55f1b9f014abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0e68c2152244cb829d47b5a962e316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=754.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe68688aa20641a48b890c80765e6369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc38eae8f8b94f43a04dc472744517c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267844284.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mypl = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mypl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fcea3781fd48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'我爱你'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'你是狗'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmypl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mypl' is not defined"
     ]
    }
   ],
   "source": [
    "a = '我爱你'\n",
    "b = '你是狗'\n",
    "print(mypl(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task:str, model:Optional=None, config:Union[str, transformers.configuration_utils.PretrainedConfig, NoneType]=None, tokenizer:Union[str, transformers.tokenization_utils.PreTrainedTokenizer, NoneType]=None, framework:Union[str, NoneType]=None, **kwargs) -> transformers.pipelines.Pipeline\n",
      "    Utility factory method to build a pipeline.\n",
      "    \n",
      "    Pipeline are made of:\n",
      "    \n",
      "        - A Tokenizer instance in charge of mapping raw textual input to token\n",
      "        - A Model instance\n",
      "        - Some (optional) post processing for enhancing model's output\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "        task (:obj:`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - \"feature-extraction\": will return a :class:`~transformers.FeatureExtractionPipeline`\n",
      "            - \"sentiment-analysis\": will return a :class:`~transformers.TextClassificationPipeline`\n",
      "            - \"ner\": will return a :class:`~transformers.NerPipeline`\n",
      "            - \"question-answering\": will return a :class:`~transformers.QuestionAnsweringPipeline`\n",
      "            - \"fill-mask\": will return a :class:`~transformers.FillMaskPipeline`\n",
      "        model (:obj:`str` or :obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`, `optional`, defaults to :obj:`None`):\n",
      "            The model that will be used by the pipeline to make predictions. This can be :obj:`None`, a string\n",
      "            checkpoint identifier or an actual pre-trained model inheriting from\n",
      "            :class:`~transformers.PreTrainedModel` for PyTorch and :class:`~transformers.TFPreTrainedModel` for\n",
      "            TensorFlow.\n",
      "    \n",
      "            If :obj:`None`, the default of the pipeline will be loaded.\n",
      "        config (:obj:`str` or :obj:`~transformers.PretrainedConfig`, `optional`, defaults to :obj:`None`):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be :obj:`None`,\n",
      "            a string checkpoint identifier or an actual pre-trained model configuration inheriting from\n",
      "            :class:`~transformers.PretrainedConfig`.\n",
      "    \n",
      "            If :obj:`None`, the default of the pipeline will be loaded.\n",
      "        tokenizer (:obj:`str` or :obj:`~transformers.PreTrainedTokenizer`, `optional`, defaults to :obj:`None`):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be :obj:`None`,\n",
      "            a string checkpoint identifier or an actual pre-trained tokenizer inheriting from\n",
      "            :class:`~transformers.PreTrainedTokenizer`.\n",
      "    \n",
      "            If :obj:`None`, the default of the pipeline will be loaded.\n",
      "        framework (:obj:`str`, `optional`, defaults to :obj:`None`):\n",
      "            The framework to use, either \"pt\" for PyTorch or \"tf\" for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified\n",
      "            and both frameworks are installed, will default to PyTorch.\n",
      "    \n",
      "    Returns:\n",
      "        :class:`~transformers.Pipeline`: Class inheriting from :class:`~transformers.Pipeline`, according to\n",
      "        the task.\n",
      "    \n",
      "    Examples::\n",
      "    \n",
      "        from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "        # Sentiment analysis pipeline\n",
      "        pipeline('sentiment-analysis')\n",
      "    \n",
      "        # Question answering pipeline, specifying the checkpoint identifier\n",
      "        pipeline('question-answering', model='distilbert-base-cased-distilled-squad', tokenizer='bert-base-cased')\n",
      "    \n",
      "        # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "        model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
      "        pipeline('ner', model=model, tokenizer=tokenizer)\n",
      "    \n",
      "        # Named entity recognition pipeline, passing a model and configuration with a HTTPS URL.\n",
      "        model_url = \"https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-large-cased-finetuned-conll03-english/pytorch_model.bin\"\n",
      "        config_url = \"https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-large-cased-finetuned-conll03-english/config.json\"\n",
      "        pipeline('ner', model=model_url, config=config_url, tokenizer='bert-base-cased')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
