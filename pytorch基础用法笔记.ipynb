{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.和numpy之间的转换\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32) torch.Size([3]) torch.Size([3]) torch.int32\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64) torch.Size([2, 3]) torch.Size([2, 3]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = torch.from_numpy(a)\n",
    "print(b,b.shape,b.size(),b.dtype)\n",
    "\n",
    "c = np.ones([2,3])\n",
    "d = torch.from_numpy(c)\n",
    "print(d, d.shape, d.size(),d.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.Size([3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]]]) torch.Size([1, 2, 3])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
      "        [0.0000e+00, 1.4013e-45, 0.0000e+00]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.Tensor(1,2,3)\n",
    "c = torch.FloatTensor(2,3)\n",
    "\n",
    "print(a, a.shape)\n",
    "print(b, b.shape)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.空张量函数 torch.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.Size([3, 4])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.Size([3, 4])\n",
      "tensor([0.]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(3,4)\n",
    "b = torch.empty([3,4])\n",
    "c = torch.empty(1)\n",
    "\n",
    "print(a, a.shape)\n",
    "print(b, b.shape)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.张量类型函数 .type()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.Size([3]) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "print(a,a.shape, a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.修改默认类型 torch.set_default_tensor_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.是否存在gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = torch.cuda.is_available()\n",
    "print(USE_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.随机初始化函数\n",
    "    rand:0,1之间均匀分布\n",
    "    randint 区间内的均匀分布\n",
    "    randn: 标准正态分布\n",
    "    normal：正态分布\n",
    "    arange：等差数列\n",
    "    linspace:等分函数\n",
    "    logspace：指数等分函数\n",
    "    ones:全1张量\n",
    "    zeros：全0张量\n",
    "    eye:主对角线1，其他0\n",
    "    full:填充函数\n",
    "    rand_like,ones_like等：形状复制函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0.6848, 0.4076, 0.6384],\n",
      "        [0.8568, 0.1162, 0.4980]]) torch.Size([2, 3])\n",
      "b: tensor([[0.9974, 0.1557, 0.7186],\n",
      "        [0.5031, 0.0849, 0.4178]]) torch.Size([2, 3])\n",
      "c: tensor([[3, 8, 8],\n",
      "        [1, 5, 9],\n",
      "        [9, 1, 8]]) torch.Size([3, 3])\n",
      "d: tensor([[-2.0809, -0.5108,  0.1621],\n",
      "        [-1.0225, -2.5722, -1.0523]]) torch.Size([2, 3])\n",
      "e: tensor([ 0.9259,  0.0640,  0.7742, -1.1569,  0.4221,  0.1038, -0.7610, -0.5172,\n",
      "         0.0906, -0.1325]) torch.Size([10])\n",
      "f: tensor([[3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.]]) torch.Size([3, 5])\n",
      "g: tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,\n",
      "        4.5000, 5.0000, 5.5000, 6.0000, 6.5000, 7.0000, 7.5000, 8.0000, 8.5000,\n",
      "        9.0000, 9.5000]) torch.Size([20])\n",
      "h: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) torch.Size([10])\n",
      "i: tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
      "         8.8889, 10.0000]) torch.Size([10])\n",
      "j: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]) torch.Size([11])\n",
      "k: tensor([   1.0000,    2.1544,    4.6416,   10.0000,   21.5443,   46.4159,\n",
      "         100.0000,  215.4435,  464.1589, 1000.0000]) torch.Size([10])\n",
      "w: tensor([   1.0000,    5.6234,   31.6228,  177.8279, 1000.0000]) torch.Size([5])\n",
      "x: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) torch.Size([2, 3])\n",
      "y: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) torch.Size([2, 3])\n",
      "z: tensor([[4., 0., 0., 0.],\n",
      "        [0., 4., 0., 0.],\n",
      "        [0., 0., 4., 0.]]) torch.Size([3, 4])\n",
      "z1: tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]) torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "\n",
    "a = torch.rand(2,3)\n",
    "b = torch.rand_like(a)\n",
    "c = torch.randint(1, 10, (3,3))\n",
    "d = torch.randn(2,3)\n",
    "e = torch.normal(mean=torch.full([10], 0), std=torch.arange(1, 0, -0.1))\n",
    "f = torch.full([3,5], 3)\n",
    "g = torch.arange(0, 10, 0.5)\n",
    "h = torch.arange(0,10) #默认差为1 \n",
    "i = torch.linspace(0, 10, steps = 10)#分10个数\n",
    "j = torch.linspace(0, 10, steps = 11)\n",
    "k = torch.logspace(0, 3, steps = 10)\n",
    "w = torch.logspace(0, 3, steps = 5)#0-1000分成5个数\n",
    "\n",
    "x = torch.ones(2,3)\n",
    "y = torch.zeros(2,3)\n",
    "z = 4 * torch.eye(3,4)\n",
    "z1 = torch.eye(4)\n",
    "print('a:', a, a.shape)\n",
    "print('b:', b, b.shape)\n",
    "print('c:', c, c.shape)\n",
    "print('d:', d, d.shape)\n",
    "print('e:', e, e.shape)\n",
    "print('f:', f, f.shape)\n",
    "print('g:', g, g.shape)\n",
    "print('h:', h, h.shape)\n",
    "print('i:', i, i.shape)\n",
    "print('j:', j, j.shape)\n",
    "print('k:', k, k.shape)\n",
    "print('w:', w, w.shape)\n",
    "print('x:', x, x.shape)\n",
    "print('y:', y, y.shape)\n",
    "print('z:', z, z.shape)\n",
    "print('z1:', z1, z1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.随机种子函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=9699): # seed的数值可以随意设置，本人不清楚有没有推荐数值\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    #根据文档，torch.manual_seed(seed)应该已经为所有设备设置seed\n",
    "    #但是torch.cuda.manual_seed(seed)在没有gpu时也可调用，这样写没什么坏处\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cuDNN在使用deterministic模式时（下面两行），可能会造成性能下降（取决于model）\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、切片和索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a torch.Size([4, 3, 28, 28])\n",
      "b torch.Size([3, 28, 28])\n",
      "c torch.Size([28, 28])\n",
      "torch.Size([])\n",
      "torch.Size([2, 3, 28, 28])\n",
      "torch.Size([2, 1, 28, 28])\n",
      "torch.Size([2, 2, 28, 28])\n",
      "torch.Size([4, 3, 14, 14])\n",
      "torch.Size([4, 3, 14, 14])\n",
      "torch.Size([2, 3, 28, 28])\n",
      "torch.Size([3, 3, 28, 28])\n",
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([3, 28, 28])\n",
      "torch.Size([4, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1111)\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "b = a[0]\n",
    "c = a[0,0]\n",
    "d = a[0,0,2,4]\n",
    "\n",
    "e = a[:2]\n",
    "f = a[:2, :1, :, :]\n",
    "g = a[:2, :-1, :, :]\n",
    "h = a[:, :, 0:28:2, 0:28:2]\n",
    "k = a[:, :, ::2, ::2]\n",
    "\n",
    "w = a.index_select(0, torch.arange(2))\n",
    "x = a.index_select(0, torch.arange(3))\n",
    "\n",
    "i = a[...]\n",
    "j = a[0, ...]\n",
    "q = a[:,2,...]\n",
    "\n",
    "print('a', a.shape)\n",
    "print('b', b.shape)\n",
    "print('c', c.shape)\n",
    "print(d.shape)\n",
    "print(e.shape)\n",
    "print(f.shape)\n",
    "print(g.shape)\n",
    "print(h.shape)\n",
    "print(k.shape)\n",
    "print(w.shape)\n",
    "print(x.shape)\n",
    "print(i.shape)\n",
    "print(j.shape)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.mask 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4078, -0.9385, -1.2721, -1.5061],\n",
      "        [ 0.8749,  0.7828,  0.5817, -0.0094],\n",
      "        [-0.2317, -1.1598,  0.8955,  0.5291]])\n",
      "tensor([[False, False, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [False, False,  True,  True]]) torch.Size([3, 4])\n",
      "tensor([0.8749, 0.7828, 0.5817, 0.8955, 0.5291]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "\n",
    "mask = x.ge(0)\n",
    "\n",
    "#mask = torch.ByteTensor(x.ge(0))\n",
    "print(mask,mask.shape)\n",
    "\n",
    "y = torch.masked_select(x, mask)\n",
    "\n",
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.take()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n",
      "tensor([1, 3, 6]) torch.Size([3])\n",
      "tensor([3]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3],[4, 5, 6]])\n",
    "print(a, a.shape)\n",
    "b = torch.take(a, torch.tensor([0, 2, 5]))\n",
    "print(b, b.shape)\n",
    "c = torch.take(a,torch.tensor([1-5]))\n",
    "print(c,c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、维度变换\n",
    "    view/reshape\n",
    "    Squeezze/unsqueeze\n",
    "    Transpose/t/permute\n",
    "    Expand/repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.view/reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4, 784])\n",
      "torch.Size([4, 28, 28])\n",
      "torch.Size([112, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(4, 1, 28, 28)\n",
    "b = a.view(4, 28*28)\n",
    "c = a.reshape(4, 28 ,28)\n",
    "d = a.reshape(4*28, 28)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.squeeze/unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([1, 4, 1, 28, 28])\n",
      "torch.Size([4, 1, 28, 28, 1])\n",
      "torch.Size([4, 1, 28, 28, 1])\n",
      "torch.Size([4, 1, 1, 28, 28])\n",
      "torch.Size([1, 4, 1, 28, 28])\n",
      "tensor([1, 2, 3]) torch.Size([3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([3, 1])\n",
      "tensor([[1, 2, 3]]) torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(4, 1, 28, 28)# 0-4, -1:-5\n",
    "\n",
    "b = a.unsqueeze(0)\n",
    "c = a.unsqueeze(-1)\n",
    "d = a.unsqueeze(4)\n",
    "e = a.unsqueeze(-4)\n",
    "f = a.unsqueeze(-5)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(e.shape)\n",
    "print(f.shape)\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = x.unsqueeze(-1)\n",
    "z = x.unsqueeze(0)\n",
    "\n",
    "print(x, x.shape)\n",
    "print(y, y.shape)\n",
    "print(z, z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 14, 14])\n",
      "torch.Size([32])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 1, 1])\n",
      "torch.Size([1, 32, 1])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "w1 = torch.rand(4, 32, 14, 14)\n",
    "b = torch.rand(32)\n",
    "\n",
    "b1 = b.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "b2 = b1.squeeze()\n",
    "b3 = b1.squeeze(0)\n",
    "b4 = b1.squeeze(-1)\n",
    "b5 = b1.squeeze(1)#不变\n",
    "b6 = b1.squeeze(-4)\n",
    "\n",
    "print(w1.shape)\n",
    "print(b.shape)\n",
    "print(b1.shape)\n",
    "print(b2.shape)\n",
    "print(b3.shape)\n",
    "print(b4.shape)\n",
    "print(b5.shape)\n",
    "print(b6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. expand/repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 14, 14])\n",
      "torch.Size([1, 32, 14, 1])\n",
      "torch.Size([1, 32, 1, -4])\n",
      "\n",
      "\n",
      "torch.Size([4, 1024, 1, 1])\n",
      "torch.Size([4, 32, 1, 1])\n",
      "torch.Size([4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 32, 14, 14)\n",
    "b = torch.rand(1, 32, 1, 1)\n",
    "\n",
    "b1 = b.expand(4, 32, 14, 14)\n",
    "b2 = b.expand(-1, 32, 14, -1)  # -1表示不变\n",
    "b3 = b.expand(-1, 32, -1, -4)  #-4是不存在的，这里是bug\n",
    "\n",
    "b4 = b.repeat(4, 32, 1, 1)\n",
    "b5 = b.repeat(4, 1, 1, 1)\n",
    "b6 = b.repeat(4, 1, 32, 32)\n",
    "\n",
    "print(b1.shape)\n",
    "print(b2.shape)\n",
    "print(b3.shape)\n",
    "print('\\n')\n",
    "print(b4.shape)\n",
    "print(b5.shape)\n",
    "print(b6.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.transpose/permute/.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 32])\n",
      "torch.Size([4, 32, 28, 3])\n",
      "torch.Size([4, 28, 32, 3])\n",
      "torch.Size([4, 28, 32, 3])\n",
      "\n",
      "\n",
      "torch.Size([3, 4])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "a = torch.rand(4, 3, 28, 32)\n",
    "\n",
    "b = a.transpose(1, 3)\n",
    "c = a.transpose(1, 3).transpose(1, 2)\n",
    "d = a.permute(0, 2, 3, 1)\n",
    "\n",
    "x = torch.randn(3, 4)\n",
    "y = x.t()\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print('\\n')\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、拼接和拆分\n",
    "    cat :合并  维度不变\n",
    "    stack：合并 维度增加\n",
    "    split：拆分 等长拆分\n",
    "    chunk：拆分 数量拆分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. cat和stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3, 32, 32])\n",
      "torch.Size([4, 4, 32, 32])\n",
      "torch.Size([4, 3, 64, 32])\n",
      "torch.Size([4, 3, 32, 64])\n",
      "\n",
      "\n",
      "torch.Size([2, 4, 3, 32, 32])\n",
      "torch.Size([4, 3, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.rand(4, 3, 32, 32)\n",
    "a2 = torch.rand(5, 3, 32, 32)\n",
    "a3 = torch.rand(4, 1, 32, 32)\n",
    "a4 = torch.rand(4, 3, 32, 32) \n",
    "\n",
    "b1 = torch.cat([a1, a2], dim=0)\n",
    "b2 = torch.cat([a1, a3], dim=1)\n",
    "b3 = torch.cat([a1, a4], dim=2)\n",
    "b4 = torch.cat([a1, a4], dim=3)\n",
    "\n",
    "b5 = torch.stack([a1, a4], dim=0)\n",
    "b6 = torch.stack([a1, a4], dim=2)\n",
    "print(b1.shape)\n",
    "print(b2.shape)\n",
    "print(b3.shape)\n",
    "print(b4.shape)\n",
    "print('\\n')\n",
    "print(b5.shape)\n",
    "print(b6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([2, 8, 8]) torch.Size([2, 8, 8]) torch.Size([2, 8, 8]) torch.Size([2, 8, 8])\n",
      "torch.Size([2, 20, 8]) torch.Size([2, 12, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "\n",
    "c = torch.stack([a, b], dim=0)\n",
    "\n",
    "c1, c2 = c.split(1, dim=0)\n",
    "c3, c4 = c.split([1, 1], dim=0)\n",
    "c5, c6, c7, c8 = c.split(8, dim=1)\n",
    "c9, c10 = c.split([20, 12], dim=1)\n",
    "\n",
    "print(c.shape)\n",
    "print(c1.shape, c2.shape)\n",
    "print(c3.shape, c4.shape)\n",
    "print(c5.shape, c6.shape, c7.shape, c8.shape)\n",
    "print(c9.shape, c10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([2, 32, 3]) torch.Size([2, 32, 3]) torch.Size([2, 32, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "\n",
    "c = torch.stack([a,b], dim=0)\n",
    "\n",
    "c1, c2 = c.chunk(2, dim=0)\n",
    "c3, c4, c5 = c.chunk(3, dim=2) \n",
    "\n",
    "print(c.shape)\n",
    "print(c1.shape, c2.shape)\n",
    "print(c3.shape, c4.shape, c5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、基本运算\n",
    "    + - * /  add\\sub\\mul\\div\n",
    "    matmul\\@\\mm(2D)\n",
    "    ** \\pow\n",
    "    sprt\\ rsqrt\n",
    "    floor\\ceil\\trunc\\frac\\round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.加减乘除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3353, 0.8036, 1.1954, 0.8062],\n",
      "        [1.8295, 1.3168, 0.8766, 1.3536],\n",
      "        [1.3892, 1.5311, 0.7067, 1.3846]])\n",
      "tensor([[1.3353, 0.8036, 1.1954, 0.8062],\n",
      "        [1.8295, 1.3168, 0.8766, 1.3536],\n",
      "        [1.3892, 1.5311, 0.7067, 1.3846]])\n",
      "tensor([[1.3353, 0.8036, 1.1954, 0.8062],\n",
      "        [1.8295, 1.3168, 0.8766, 1.3536],\n",
      "        [1.3892, 1.5311, 0.7067, 1.3846]])\n",
      "\n",
      "\n",
      "tensor(True) tensor(True) tensor(True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(4)\n",
    "\n",
    "c = a + b\n",
    "c1 = a.add(b)\n",
    "c2 = torch.add(a, b)\n",
    "\n",
    "c4 = torch.all(torch.eq(a-b, torch.sub(a, b)))\n",
    "c5 = torch.all(torch.eq(a*b, torch.mul(a, b))) \n",
    "c6 = torch.all(torch.eq(a/b, a.div(b)))\n",
    "\n",
    "print(c)\n",
    "print(c1)\n",
    "print(c2)\n",
    "print('\\n')\n",
    "print(c4, c5, c6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "\n",
      "\n",
      "torch.Size([4, 3, 28, 128])\n",
      "torch.Size([4, 3, 28, 128])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "a = 3 * torch.ones(2, 2)\n",
    "b = torch.ones(2, 2)\n",
    "\n",
    "c = torch.mm(a, b)\n",
    "c1 = torch.matmul(a, b)\n",
    "c2 = a @ b\n",
    "\n",
    "x = torch.rand(4, 3, 28, 64)\n",
    "y = torch.rand(4, 3, 64, 128)\n",
    "y1 = torch.rand(4, 1, 64, 128)\n",
    "\n",
    "z1 = torch.matmul(x, y)\n",
    "z2 = torch.matmul(x, y1)\n",
    "\n",
    "print(c)\n",
    "print(c1)\n",
    "print(c2)\n",
    "print('\\n')\n",
    "print(z1.shape)\n",
    "print(z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 指数函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]]) \n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]]) \n",
      " tensor([[9., 9.],\n",
      "        [9., 9.]]) \n",
      " tensor([[3., 3.],\n",
      "        [3., 3.]]) \n",
      " tensor([[0.3333, 0.3333],\n",
      "        [0.3333, 0.3333]]) \n",
      " tensor([[4.7288, 4.7288],\n",
      "        [4.7288, 4.7288]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1111)\n",
    "a = torch.full([2, 2], 3)\n",
    "\n",
    "b = a.pow(2)\n",
    "c = a.pow(0)\n",
    "b1 = a**2\n",
    "b2 = (a**2).sqrt()\n",
    "b3 = (a**2).rsqrt() # 平方根倒数\n",
    "b4 = a**2**(0.5) \n",
    "print(b, '\\n', c, '\\n', b1, '\\n', b2, '\\n', b3, '\\n', b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.对数函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7183, 2.7183],\n",
      "        [2.7183, 2.7183]])\n",
      "tensor([[256., 256.],\n",
      "        [256., 256.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[8., 8.],\n",
      "        [8., 8.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "\n",
    "a = torch.exp(torch.ones(2, 2))\n",
    "a1 = 2** (torch.ones(2,2)*8)\n",
    "\n",
    "b = torch.log(a)\n",
    "c = torch.log2(a1)\n",
    "print(a)\n",
    "print(a1)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.近似解\n",
    "    floor():向下取整\n",
    "    ceil():向上取整\n",
    "    trunc():取整数部分\n",
    "    frac():取小数部分\n",
    "    round()：四舍五入（0.5 舍去）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1400)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor(3.)\n",
      "tensor(0.1400)\n",
      "\n",
      "\n",
      "tensor(3.)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(3.14)\n",
    "\n",
    "b = a.floor()\n",
    "c = a.ceil()\n",
    "d = a.trunc()\n",
    "e = a.frac()\n",
    "\n",
    "x = torch.tensor(3.499)\n",
    "y = torch.tensor(4.510)\n",
    "\n",
    "z1 = x.round()\n",
    "z2 = y.round()\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)\n",
    "print('\\n')\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.取特殊值\n",
    "    clamp:范围取值，可构造relu函数\n",
    "    min:最小值\n",
    "    max：最大值\n",
    "    median：中间值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3030, 0.4249, 4.0047],\n",
      "        [1.9859, 4.7740, 2.9909]])\n",
      "tensor(4.7740)\n",
      "tensor(2.3030)\n",
      "tensor([0, 2, 3, 0])\n",
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n",
      "tensor([[2.3030, 0.4249, 4.0047],\n",
      "        [1.9859, 4.7740, 2.9909]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "a = torch.rand(2, 3) * 5\n",
    "a1 = torch.tensor([-1, 2, 3, -4])\n",
    "\n",
    "b = a.max()\n",
    "c = a.median()\n",
    "\n",
    "d = a1.clamp(0) #relu\n",
    "d1 = a.clamp(10)\n",
    "d2 = a.clamp(0, 10)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)   \n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、统计数据\n",
    "    norm:范数 1，2\n",
    "    mean：均值、sum:累加、prod:累乘\n",
    "    max;最大、min：最小、argmax:最大值对应索引、argmin:最小值对应索引\n",
    "    topk:较大的几个 kthvalue:较小的几个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.]) \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      " tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "tensor(8.) tensor(8.) tensor(8.)\n",
      "tensor(2.8284) tensor(2.8284) tensor(2.8284)\n",
      "tensor([4., 4.]) tensor([2., 2.])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]]) \n",
      " tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.full([8], 1)\n",
    "\n",
    "b = a.view(2, 4)\n",
    "c = a.reshape(2, 2, 2)\n",
    "\n",
    "d1, d2, d3 = a.norm(1), b.norm(1), c.norm(1)\n",
    "e1, e2, e3 = a.norm(2), b.norm(2), c.norm(2)\n",
    "\n",
    "f1 = b.norm(1, dim=1)\n",
    "f2 = b.norm(2, dim=1)\n",
    "\n",
    "h1 = c.norm(1, dim=0)\n",
    "h2 = c.norm(2, dim=0)\n",
    "\n",
    "print(a, '\\n', b, '\\n', c)\n",
    "print(d1, d2, d3)\n",
    "print(e1, e2, e3)\n",
    "print(f1, f2)\n",
    "print(h1, '\\n', h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.常见取特殊值函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]]) \n",
      " tensor(3.5000) tensor(28.) tensor(0.) tensor(7.) tensor(0.) tensor(7) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "\n",
    "a = torch.arange(8).reshape(2, 4).float()\n",
    "\n",
    "b1, b2, b3, b4, b5, b6, b7 = a.mean(), a.sum(), a.prod(), a.max(), a.min(), a.argmax(), a.argmin()\n",
    "\n",
    "print(a, '\\n', b1,b2,b3,b4,b5,b6,b7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1065,  0.1614, -0.6850,  0.9943,  1.7562, -0.2647, -0.9040, -2.0230,\n",
      "         -0.1012, -0.3893],\n",
      "        [ 1.6611, -0.1536, -1.7632, -1.3242,  0.7061,  1.3013, -0.8899, -0.0195,\n",
      "         -0.5017, -0.0746],\n",
      "        [-0.8013, -0.0597, -0.6181,  0.0434,  1.3775,  0.2325,  0.5974,  1.6458,\n",
      "          0.6398, -1.4972],\n",
      "        [ 0.0246,  0.1690,  0.2091, -0.3026, -0.1032, -0.2076, -0.7478,  1.3935,\n",
      "          0.4201,  0.2469]])\n",
      "tensor(4) tensor([4, 0, 7, 7]) tensor([0, 1, 1, 1, 3, 0, 0, 0, 1, 2]) \n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([1.7562, 1.6611, 1.6458, 1.3935]),\n",
      "indices=tensor([4, 0, 7, 7])) \n",
      " tensor([4, 0, 7, 7]) \n",
      " torch.return_types.max(\n",
      "values=tensor([[1.7562],\n",
      "        [1.6611],\n",
      "        [1.6458],\n",
      "        [1.3935]]),\n",
      "indices=tensor([[4],\n",
      "        [0],\n",
      "        [7],\n",
      "        [7]])) \n",
      " tensor([[4],\n",
      "        [0],\n",
      "        [7],\n",
      "        [7]])\n",
      "\n",
      " torch.return_types.topk(\n",
      "values=tensor([[1.7562, 0.9943, 0.1614],\n",
      "        [1.6611, 1.3013, 0.7061],\n",
      "        [1.6458, 1.3775, 0.6398],\n",
      "        [1.3935, 0.4201, 0.2469]]),\n",
      "indices=tensor([[4, 3, 1],\n",
      "        [0, 5, 4],\n",
      "        [7, 4, 8],\n",
      "        [7, 8, 9]])) \n",
      " torch.return_types.topk(\n",
      "values=tensor([[1.7562, 0.9943, 0.1614],\n",
      "        [1.6611, 1.3013, 0.7061],\n",
      "        [1.6458, 1.3775, 0.6398],\n",
      "        [1.3935, 0.4201, 0.2469]]),\n",
      "indices=tensor([[4, 3, 1],\n",
      "        [0, 5, 4],\n",
      "        [7, 4, 8],\n",
      "        [7, 8, 9]])) \n",
      " torch.return_types.topk(\n",
      "values=tensor([[-2.0230, -1.1065, -0.9040],\n",
      "        [-1.7632, -1.3242, -0.8899],\n",
      "        [-1.4972, -0.8013, -0.6181],\n",
      "        [-0.7478, -0.3026, -0.2076]]),\n",
      "indices=tensor([[7, 0, 6],\n",
      "        [2, 3, 6],\n",
      "        [9, 0, 2],\n",
      "        [6, 3, 5]]))\n",
      "\n",
      " torch.return_types.kthvalue(\n",
      "values=tensor([-0.9040, -0.8899, -0.6181, -0.2076]),\n",
      "indices=tensor([6, 6, 2, 5])) \n",
      " torch.return_types.kthvalue(\n",
      "values=tensor([-0.9040, -0.8899, -0.6181, -0.2076]),\n",
      "indices=tensor([6, 6, 2, 5])) \n",
      " torch.return_types.kthvalue(\n",
      "values=tensor([0.1614, 0.7061, 0.6398, 0.2469]),\n",
      "indices=tensor([1, 4, 8, 9]))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "a = torch.randn(4, 10)\n",
    "\n",
    "c1 = a.argmax()\n",
    "c2 = a.argmax(dim=1)\n",
    "c3 = a.argmin(dim=0)\n",
    "\n",
    "d1 = a.max(dim = 1)\n",
    "d2 = a.argmax(dim=1)\n",
    "d3 = a.max(dim=1, keepdim=True)\n",
    "d4 = a.argmax(dim=1, keepdim=True)\n",
    "\n",
    "e1 = a.topk(3)\n",
    "e2 = a.topk(3, dim=1)\n",
    "e3 = a.topk(3, dim=1, largest=False)\n",
    "\n",
    "f1 = a.kthvalue(3)\n",
    "f2 = a.kthvalue(3, dim=1)\n",
    "f3 = a.kthvalue(8, dim=1)\n",
    "\n",
    "print(a)\n",
    "print(c1,c2,c3,'\\n')\n",
    "print(d1,'\\n',d2,'\\n',d3,'\\n',d4)\n",
    "print('\\n', e1,'\\n', e2,'\\n', e3)\n",
    "print('\\n', f1, '\\n', f2, '\\n', f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.比较运算\n",
    "    >  >= < <= != ==\n",
    "    torch.eq(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]]) \n",
      " tensor([[True, True, True],\n",
      "        [True, True, True]]) \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "a = torch.arange(8).view(2, 4).float()\n",
    "\n",
    "b = torch.ones(2, 3)\n",
    "c = torch.randn(2, 3)\n",
    "\n",
    "d1 = torch.eq(b, c)\n",
    "d2 = torch.eq(b, b)\n",
    "d3 = torch.equal(b, b)\n",
    "\n",
    "print(a > 0)\n",
    "print(torch.gt(a, 0))\n",
    "print(a != 0)\n",
    "print(d1, '\\n', d2, '\\n', d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、 激活函数和梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True)\n",
      "tensor(1.)\n",
      "tensor([2.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1017,  0.1702, -0.0685]),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "x = torch.ones(1)\n",
    "w = torch.full([1], 2)\n",
    "mse = F.mse_loss(torch.ones(1), x*w)\n",
    "w_grad = w.requires_grad_()\n",
    "print(w_grad)\n",
    "print(mse)\n",
    "\n",
    "mse2 = F.mse_loss(torch.ones(1), x*w)\n",
    "mse2.backward()\n",
    "w2 = w.grad\n",
    "print(w2)\n",
    "\n",
    "a = torch.rand(3)\n",
    "a.requires_grad_()\n",
    "\n",
    "p = F.softmax(a, dim=0)\n",
    "torch.autograd.grad(p[1], [a],retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
